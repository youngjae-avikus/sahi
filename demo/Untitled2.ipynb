{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17aa5ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 24 01:09:21 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA Graphics...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   62C    P3     6W /  N/A |   1911MiB /  3913MiB |      5%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1147      G   /usr/lib/xorg/Xorg                 44MiB |\r\n",
      "|    0   N/A  N/A      1403      G   /usr/bin/gnome-shell                5MiB |\r\n",
      "|    0   N/A  N/A      1867      G   /usr/lib/xorg/Xorg                325MiB |\r\n",
      "|    0   N/A  N/A      2040      G   /usr/bin/gnome-shell              189MiB |\r\n",
      "|    0   N/A  N/A      3991      G   ...818280098758357408,131072      347MiB |\r\n",
      "|    0   N/A  N/A      7125    C+G   /usr/bin/python3                  884MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "602234c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yyj/sahi/demo'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e83ae3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange an instance segmentation model for test\n",
    "from sahi.utils.yolov5 import (\n",
    "    download_yolov5s6_model,\n",
    ")\n",
    "\n",
    "# import required functions, classes\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.utils.cv import read_image\n",
    "from sahi.utils.file import download_from_url\n",
    "from sahi.predict import get_prediction, get_sliced_prediction, predict\n",
    "from IPython.display import Image\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c24fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_image_dir = \"../resources/FLL_VAL/images/\"\n",
    "image_files = sorted([fn for fn in os.listdir(source_image_dir) if fn.endswith(\"jpg\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57183c3f",
   "metadata": {},
   "source": [
    "## Standard Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b41676",
   "metadata": {},
   "outputs": [],
   "source": [
    "DSL_STANDARD_JSON_FILE = '../resources/DSL/result_FL221022_0.25_standard_pred.json'\n",
    "\n",
    "with open(DSL_STANDARD_JSON_FILE, 'r') as f:\n",
    "    datas = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb1fc035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b270de7e845943bba51bc9049bc541b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=4896), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "\n",
    "@interact(index=(0, len(image_files)-1))\n",
    "def show_sample(index=0):\n",
    "    infos = [ data for data in datas if data['image_id'] == index ]\n",
    "    image_path = os.path.join(source_image_dir, image_files[index])\n",
    "    image = cv2.imread(image_path)    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    for info in infos:\n",
    "        bbox = list(map(int, info['bbox']))\n",
    "        category_name =  info['category_name']\n",
    "        conf = info['score']\n",
    "        label = f\"{category_name} {conf:.2f}\"\n",
    "        \n",
    "        cv2.rectangle(image,\n",
    "                      bbox[:2],\n",
    "                      [ bbox1 + bbox2 for bbox1, bbox2 in zip(bbox[:2], bbox[2:])],\n",
    "                      color=(255, 0, 0),\n",
    "                      thickness=2)\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            label,  \n",
    "            [bbox[0], bbox[1]-10],\n",
    "            0,\n",
    "            1,\n",
    "            (255, 255, 255),\n",
    "            thickness=3,\n",
    "        )\n",
    "        \n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f7d4b",
   "metadata": {},
   "source": [
    "## Slice Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cd43ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DSL_SLICE_JSON_FILE = '../resources/DSL/result_slice_pred.json'\n",
    "\n",
    "with open(DSL_SLICE_JSON_FILE, 'r') as f:\n",
    "    datas = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f125f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_slice_x_start=640\n",
    "custom_slice_y_start=360\n",
    "slice_size=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "912a9509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8f192787244ac79014f2d99ca58b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=4896), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "\n",
    "@interact(index=(0, len(image_files)-1))\n",
    "def show_sample(index=0):\n",
    "    infos = [ data for data in datas if data['image_id'] == index ]\n",
    "    image_path = os.path.join(source_image_dir, image_files[index])\n",
    "    image = cv2.imread(image_path)    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    for info in infos:\n",
    "        bbox = list(map(int, info['bbox']))\n",
    "        category_name =  info['category_name']\n",
    "        conf = info['score']\n",
    "        label = f\"{category_name} {conf:.2f}\"\n",
    "        \n",
    "        cv2.rectangle(image,\n",
    "                      bbox[:2],\n",
    "                      [ bbox1 + bbox2 for bbox1, bbox2 in zip(bbox[:2], bbox[2:])],\n",
    "                      color=(255, 0, 0),\n",
    "                      thickness=2)\n",
    "        \n",
    "        cv2.rectangle(image,\n",
    "                      [custom_slice_x_start, custom_slice_y_start],\n",
    "                      [custom_slice_x_start+slice_size, custom_slice_y_start+slice_size],\n",
    "                      color=(0, 255, 0),\n",
    "                      thickness=2)\n",
    "        \n",
    "        cv2.putText(\n",
    "            image,\n",
    "            label,  \n",
    "            [bbox[0], bbox[1]-10],\n",
    "            0,\n",
    "            1,\n",
    "            (255, 255, 255),\n",
    "            thickness=3,\n",
    "        )\n",
    "        \n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e475f",
   "metadata": {},
   "source": [
    "## Compare Standard and Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b5c31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "DSL_STANDARD_JSON_FILE = '../resources/DSL/result_FL221022_0.25_standard_pred.json'\n",
    "DSL_SLICE_JSON_FILE = '../resources/DSL/result_slice_pred.json'\n",
    "\n",
    "with open(DSL_STANDARD_JSON_FILE, 'r') as f:\n",
    "    standard_datas = json.load(f)\n",
    "\n",
    "with open(DSL_SLICE_JSON_FILE, 'r') as f:\n",
    "    slice_datas = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38e012af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f639afdfc145da80378ee7ac6b9e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=4896), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "\n",
    "    \n",
    "@interact(index=(0, len(image_files)-1))\n",
    "def show_sample(index=0):\n",
    "    standard_infos = [ data for data in standard_datas if data['image_id'] == index ]\n",
    "    slice_infos = [ data for data in slice_datas if data['image_id'] == index ]\n",
    "    \n",
    "    image_path = os.path.join(source_image_dir, image_files[index])\n",
    "    image1 = cv2.imread(image_path)    \n",
    "    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    for info in standard_infos:\n",
    "        bbox = list(map(int, info['bbox']))\n",
    "        category_name =  info['category_name']\n",
    "        conf = info['score']\n",
    "        label = f\"{category_name} {conf:.2f}\"\n",
    "        \n",
    "        cv2.rectangle(image1,\n",
    "                      bbox[:2],\n",
    "                      [ bbox1 + bbox2 for bbox1, bbox2 in zip(bbox[:2], bbox[2:])],\n",
    "                      color=(255, 0, 0),\n",
    "                      thickness=2)\n",
    "        \n",
    "        cv2.putText(\n",
    "            image1,\n",
    "            label,  \n",
    "            [bbox[0], bbox[1]-10],\n",
    "            0,\n",
    "            1,\n",
    "            (255, 255, 255),\n",
    "            thickness=3,\n",
    "        )\n",
    "    \n",
    "    image_path = os.path.join(source_image_dir, image_files[index])\n",
    "    image2 = cv2.imread(image_path)    \n",
    "    image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    \n",
    "    for info in slice_infos:\n",
    "        bbox = list(map(int, info['bbox']))\n",
    "        category_name =  info['category_name']\n",
    "        conf = info['score']\n",
    "        label = f\"{category_name} {conf:.2f}\"\n",
    "        \n",
    "        cv2.rectangle(image2,\n",
    "                      bbox[:2],\n",
    "                      [ bbox1 + bbox2 for bbox1, bbox2 in zip(bbox[:2], bbox[2:])],\n",
    "                      color=(255, 0, 0),\n",
    "                      thickness=2)\n",
    "        \n",
    "        cv2.rectangle(image2,\n",
    "                      [custom_slice_x_start, custom_slice_y_start],\n",
    "                      [custom_slice_x_start+slice_size, custom_slice_y_start+slice_size],\n",
    "                      color=(0, 255, 0),\n",
    "                      thickness=2)\n",
    "        \n",
    "        cv2.putText(\n",
    "            image2,\n",
    "            label,  \n",
    "            [bbox[0], bbox[1]-10],\n",
    "            0,\n",
    "            1,\n",
    "            (255, 255, 255),\n",
    "            thickness=3,\n",
    "        )\n",
    "        \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(32,32)) \n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "    \n",
    "    axes[0].axis('off')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[0].imshow(image1)\n",
    "    axes[1].imshow(image2)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a0120d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "871665c3",
   "metadata": {},
   "source": [
    "## Slice Prediction (SAHI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fcdd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_slice_x_start=640\n",
    "custom_slice_y_start=360\n",
    "custom_slice_mode=2\n",
    "slice_size=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd92e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fll_model_221014_path = '../resources/models/221014/best.pt'\n",
    "\n",
    "fll_model_221014 = AutoDetectionModel.from_pretrained(\n",
    "    model_type='yolov5',\n",
    "    model_path=fll_model_221014_path,\n",
    "    confidence_threshold=0.25,\n",
    "    device=\"cuda:0\"\n",
    ")\n",
    "\n",
    "model = fll_model_221014\n",
    "model_path = fll_model_221014_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48846fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi.utils.cv import Colors\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def visualize_object_predictions(\n",
    "    image: np.array,\n",
    "    object_prediction_list,\n",
    "    rect_th: int = None,\n",
    "    text_size: float = None,\n",
    "    text_th: float = None,\n",
    "    color: tuple = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes prediction category names, bounding boxes over the source image\n",
    "    and exports it to output folder.\n",
    "    Arguments:\n",
    "        object_prediction_list: a list of prediction.ObjectPrediction\n",
    "        rect_th: rectangle thickness\n",
    "        text_size: size of the category name over box\n",
    "        text_th: text thickness\n",
    "        color: annotation color in the form: (0, 255, 0)\n",
    "        output_dir: directory for resulting visualization to be exported\n",
    "        file_name: exported file will be saved as: output_dir+file_name+\".png\"\n",
    "        export_format: can be specified as 'jpg' or 'png'\n",
    "    \"\"\"\n",
    "    # deepcopy image so that original is not altered\n",
    "    image = copy.deepcopy(image)\n",
    "    # select predefined classwise color palette if not specified\n",
    "    if color is None:\n",
    "        colors = Colors()\n",
    "    else:\n",
    "        colors = None\n",
    "    # set rect_th for boxes\n",
    "    rect_th = rect_th or max(round(sum(image.shape) / 2 * 0.001), 1)\n",
    "    # set text_th for category names\n",
    "    text_th = text_th or max(rect_th - 1, 1)\n",
    "    # set text_size for category names\n",
    "    text_size = text_size or rect_th / 3\n",
    "    # add bbox and mask to image if present\n",
    "    for object_prediction in object_prediction_list:\n",
    "        # deepcopy object_prediction_list so that original is not altered\n",
    "        object_prediction = object_prediction.deepcopy()\n",
    "\n",
    "        bbox = object_prediction.bbox.to_voc_bbox()\n",
    "        category_name = object_prediction.category.name\n",
    "        score = object_prediction.score.value\n",
    "\n",
    "        # set color\n",
    "        if colors is not None:\n",
    "            color = colors(object_prediction.category.id)\n",
    "        # visualize masks if present\n",
    "        if object_prediction.mask is not None:\n",
    "            # deepcopy mask so that original is not altered\n",
    "            mask = object_prediction.mask.bool_mask\n",
    "            # draw mask\n",
    "            rgb_mask = apply_color_mask(mask, color)\n",
    "            image = cv2.addWeighted(image, 1, rgb_mask, 0.4, 0)\n",
    "        # set bbox points\n",
    "        p1, p2 = (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3]))\n",
    "        # visualize boxes\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            p1,\n",
    "            p2,\n",
    "            color=color,\n",
    "            thickness=rect_th\n",
    "        )\n",
    "        # arange bounding box text location\n",
    "        label = f\"{category_name} {score:.2f}\"\n",
    "        w, h = cv2.getTextSize(label, 0, fontScale=text_size, thickness=text_th)[0]  # label width, height\n",
    "        outside = p1[1] - h - 3 >= 0  # label fits outside box\n",
    "        p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "        # add bounding box text\n",
    "        cv2.rectangle(image, p1, p2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            label,\n",
    "            (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n",
    "            0,\n",
    "            text_size,\n",
    "            (255, 255, 255),\n",
    "            thickness=text_th,\n",
    "        )\n",
    "        \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236ab086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from sahi.slicing import slice_image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "@interact(index=(0, len(image_files)-1), slice_size=(0, 512), overlap_ratio=(0, 0.5, 0.05), only_full_inference=(0,1))\n",
    "def show_sample(index=0, slice_size=512, overlap_ratio=0.2, only_full_inference=0):\n",
    "    image_file = image_files[index]\n",
    "    image_path = os.path.join(source_image_dir, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if not only_full_inference:\n",
    "        slice_result = slice_image(image_path, \n",
    "                                  slice_width=slice_size,\n",
    "                                  slice_height=slice_size,\n",
    "                                  overlap_height_ratio=overlap_ratio,\n",
    "                                  overlap_width_ratio=overlap_ratio,\n",
    "                                  custom_slice_mode=custom_slice_mode,\n",
    "                                  custom_slice_x_start=custom_slice_x_start,\n",
    "                                  custom_slice_y_start=custom_slice_y_start,\n",
    "                                  verbose=1)\n",
    "\n",
    "        for start_pixel in slice_result.starting_pixels:\n",
    "            cv2.rectangle(image,\n",
    "                          start_pixel,\n",
    "                          [s1+s2 for s1, s2 in zip(start_pixel,[slice_size,slice_size])],\n",
    "                          color=(255, 255, 0),\n",
    "                          thickness=2)\n",
    "        \n",
    "        result = get_sliced_prediction(image_path,\n",
    "                                       model,\n",
    "                                       slice_height=slice_size,\n",
    "                                       slice_width=slice_size,\n",
    "                                       postprocess_match_threshold=0.5,\n",
    "                                       overlap_height_ratio=overlap_ratio,\n",
    "                                       overlap_width_ratio=overlap_ratio,\n",
    "                                       custom_slice_mode=custom_slice_mode,\n",
    "                                       postprocess_type=\"GREEDYNMM\",\n",
    "                                       custom_slice_x_start=custom_slice_x_start,\n",
    "                                       custom_slice_y_start=custom_slice_y_start\n",
    "                                      )\n",
    "    else:\n",
    "        result = get_prediction(image_path, model)\n",
    "    \n",
    "    canvas = visualize_object_predictions(image, result.object_prediction_list)\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3701be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
