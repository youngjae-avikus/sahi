{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eebc0d0",
   "metadata": {},
   "source": [
    "# 1. 비디오 불러와서 프레임 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb07ec09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yyj/sahi/demo'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9ba4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def extract_frame(video_path, frame_dir, overwrite=False, start=-1, end=-1, every=1):\n",
    "    \"\"\"\n",
    "    Extract frames from a video using OpenCVs VideoCapture\n",
    "    :param video_path: path of the video\n",
    "    :param frames_dir: the directory to save the frames\n",
    "    :param overwrite: to overwrite frames that already exist?\n",
    "    :param start: start frame\n",
    "    :param end: end frame\n",
    "    :param every: frame spacing\n",
    "    :return: count of images saved\n",
    "    \"\"\"\n",
    "    \n",
    "    video_path = os.path.normpath(video_path)\n",
    "    frame_dir = os.path.normpath(frame_dir)\n",
    "    \n",
    "    video_dir, video_filename = os.path.split(video_path)\n",
    "    video_filename = os.path.splitext(video_filename)[0]\n",
    "    assert os.path.exists(video_path)\n",
    "    \n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if start < 0:\n",
    "        start = 0\n",
    "    if end < 0:\n",
    "        end = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "    print(fps)\n",
    "    \n",
    "    capture.set(cv2.CAP_PROP_FPS,30) \n",
    "    print(capture.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    print(start, end)\n",
    "    capture.set(1, start)\n",
    "    frame = start\n",
    "    while_safety = 0\n",
    "    saved_count = 0 \n",
    "    \n",
    "    while frame < end:\n",
    "        if while_safety > 10:  # break the while if our safety maxs out at 10\n",
    "            break\n",
    "        \n",
    "        _, image = capture.read()\n",
    "        \n",
    "        if frame % every == 0:\n",
    "           \n",
    "            if image is None:\n",
    "                print(\"Image is None\")\n",
    "                while_safety += 1\n",
    "                continue\n",
    "            \n",
    "            while_safety = 0\n",
    "            \n",
    "            save_path = os.path.join(frame_dir, video_filename, \"{:010d}.jpg\".format(saved_count))\n",
    "            \n",
    "            if not os.path.exists(os.path.join(frame_dir, video_filename)):\n",
    "                os.makedirs(os.path.join(frame_dir, video_filename))\n",
    "            if not os.path.exists(save_path) or overwrite:\n",
    "                cv2.imwrite(save_path, image)\n",
    "                saved_count += 1\n",
    "                \n",
    "        frame += 1\n",
    "        \n",
    "    capture.release()\n",
    "        \n",
    "    return saved_count, os.path.join(frame_dir, video_filename);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7439f748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.467068557812325\n",
      "30.467068557812325\n",
      "0 31168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x55d63f40a500] decode_slice_header error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image is None\n",
      "Image is None\n",
      "Image is None\n",
      "Image is None\n",
      "Image is None\n",
      "Image is None\n",
      "Image is None\n",
      "Image is None\n",
      "Image is None\n",
      "Image is None\n",
      "Image is None\n"
     ]
    }
   ],
   "source": [
    "video_path = \"../resources/FL_221024_3.mp4\"\n",
    "frame_dirs = \"../resources/export_frame\"\n",
    "\n",
    "_, source_image_dir = extract_frame(video_path, frame_dirs, every=30, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b58939",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_image_dir = \"../resources/FLL_VAL/images/\"\n",
    "source_label_dir = \"../resources/FLL_VAL/labels/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71429758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../resources/export_frame/FL_221024'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_image_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f1e191",
   "metadata": {},
   "source": [
    "# 2. 비디오 인퍼런스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649c59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange an instance segmentation model for test\n",
    "from sahi.utils.yolov5 import (\n",
    "    download_yolov5s6_model,\n",
    ")\n",
    "\n",
    "# import required functions, classes\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.utils.cv import read_image\n",
    "from sahi.utils.file import download_from_url\n",
    "from sahi.predict import get_prediction, get_sliced_prediction, predict\n",
    "from sahi.scripts.coco_error_analysis import analyse\n",
    "from sahi.scripts.coco_evaluation import evaluate\n",
    "from sahi.slicing import slice_image\n",
    "from IPython.display import Image\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d075d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "fll_model_221023_path = '../resources/models/221023_960/best.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b300a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fll_model_221023 = AutoDetectionModel.from_pretrained(\n",
    "    model_type='yolov5',\n",
    "    model_path=fll_model_221023_path,\n",
    "    confidence_threshold=0.25,\n",
    "    device=\"cuda:0\",\n",
    "    image_size=960\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc0e53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fll_model_221023\n",
    "model_path = fll_model_221023_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11f620",
   "metadata": {},
   "source": [
    "## Interact로 인퍼런스 샘플 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e88a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi.utils.cv import Colors\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def visualize_object_predictions(\n",
    "    image: np.array,\n",
    "    object_prediction_list,\n",
    "    rect_th: int = None,\n",
    "    text_size: float = None,\n",
    "    text_th: float = None,\n",
    "    color: tuple = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes prediction category names, bounding boxes over the source image\n",
    "    and exports it to output folder.\n",
    "    Arguments:\n",
    "        object_prediction_list: a list of prediction.ObjectPrediction\n",
    "        rect_th: rectangle thickness\n",
    "        text_size: size of the category name over box\n",
    "        text_th: text thickness\n",
    "        color: annotation color in the form: (0, 255, 0)\n",
    "        output_dir: directory for resulting visualization to be exported\n",
    "        file_name: exported file will be saved as: output_dir+file_name+\".png\"\n",
    "        export_format: can be specified as 'jpg' or 'png'\n",
    "    \"\"\"\n",
    "    # deepcopy image so that original is not altered\n",
    "    image = copy.deepcopy(image)\n",
    "    # select predefined classwise color palette if not specified\n",
    "    if color is None:\n",
    "        colors = Colors()\n",
    "    else:\n",
    "        colors = None\n",
    "    # set rect_th for boxes\n",
    "    rect_th = rect_th or max(round(sum(image.shape) / 2 * 0.001), 1)\n",
    "    # set text_th for category names\n",
    "    text_th = text_th or max(rect_th - 1, 1)\n",
    "    # set text_size for category names\n",
    "    text_size = text_size or rect_th / 3\n",
    "    # add bbox and mask to image if present\n",
    "    for object_prediction in object_prediction_list:\n",
    "        # deepcopy object_prediction_list so that original is not altered\n",
    "        object_prediction = object_prediction.deepcopy()\n",
    "\n",
    "        bbox = object_prediction.bbox.to_voc_bbox()\n",
    "        category_name = object_prediction.category.name\n",
    "        score = object_prediction.score.value\n",
    "\n",
    "        # set color\n",
    "        if colors is not None:\n",
    "            color = colors(object_prediction.category.id)\n",
    "        # visualize masks if present\n",
    "        if object_prediction.mask is not None:\n",
    "            # deepcopy mask so that original is not altered\n",
    "            mask = object_prediction.mask.bool_mask\n",
    "            # draw mask\n",
    "            rgb_mask = apply_color_mask(mask, color)\n",
    "            image = cv2.addWeighted(image, 1, rgb_mask, 0.4, 0)\n",
    "        # set bbox points\n",
    "        p1, p2 = (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3]))\n",
    "        # visualize boxes\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            p1,\n",
    "            p2,\n",
    "            color=color,\n",
    "            thickness=rect_th\n",
    "        )\n",
    "        # arange bounding box text location\n",
    "        label = f\"{category_name} {score:.2f}\"\n",
    "        w, h = cv2.getTextSize(label, 0, fontScale=text_size, thickness=text_th)[0]  # label width, height\n",
    "        outside = p1[1] - h - 3 >= 0  # label fits outside box\n",
    "        p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "        # add bounding box text\n",
    "        cv2.rectangle(image, p1, p2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            label,\n",
    "            (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n",
    "            0,\n",
    "            text_size,\n",
    "            (255, 255, 255),\n",
    "            thickness=text_th,\n",
    "        )\n",
    "        \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccd660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "image_files = sorted(os.listdir(source_image_dir))\n",
    "\n",
    "@interact(index=(0, len(image_files)-1),\n",
    "          slice_size=(0, 640),\n",
    "          overlap_ratio=(0, 0.5, 0.05),\n",
    "          custom_slice_x_start=(0, 640),\n",
    "          custom_slice_y_start=(0, 512),\n",
    "          custom_slice_mode=(0,3),\n",
    "          only_full_inference=(0,1))\n",
    "def show_sample(index=0, slice_size=640, overlap_ratio=0.25,\n",
    "                custom_slice_x_start=640, custom_slice_y_start=360, custom_slice_mode=2,\n",
    "                only_full_inference=0):\n",
    "    image_file = image_files[index]\n",
    "    image_path = os.path.join(source_image_dir, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if not only_full_inference:\n",
    "        slice_result = slice_image(image_path, \n",
    "                                  slice_width=slice_size,\n",
    "                                  slice_height=slice_size,\n",
    "                                  overlap_height_ratio=overlap_ratio,\n",
    "                                  overlap_width_ratio=overlap_ratio,\n",
    "                                  custom_slice_x_start=custom_slice_x_start,\n",
    "                                  custom_slice_y_start=custom_slice_y_start,\n",
    "                                  custom_slice_mode=custom_slice_mode,\n",
    "                                  verbose=1)\n",
    "\n",
    "        for start_pixel in slice_result.starting_pixels:\n",
    "            cv2.rectangle(image,\n",
    "                          start_pixel,\n",
    "                          [s1+s2 for s1, s2 in zip(start_pixel,[slice_size,slice_size])],\n",
    "                          color=(255, 255, 0),\n",
    "                          thickness=2)\n",
    "        \n",
    "        result = get_sliced_prediction(image_path,\n",
    "                                       model,\n",
    "                                       slice_height=slice_size,\n",
    "                                       slice_width=slice_size,\n",
    "                                       postprocess_match_threshold=0.5,\n",
    "                                       overlap_height_ratio=overlap_ratio,\n",
    "                                       overlap_width_ratio=overlap_ratio,\n",
    "                                       custom_slice_x_start=custom_slice_x_start,\n",
    "                                       custom_slice_y_start=custom_slice_y_start,\n",
    "                                       custom_slice_mode=custom_slice_mode\n",
    "                                      )\n",
    "    else:\n",
    "        result = get_prediction(image_path, model)\n",
    "    \n",
    "    canvas = visualize_object_predictions(image, result.object_prediction_list)\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_extract(img_dir, label_dir, out_dir):\n",
    "    if os.path.exists(os.path.join(out_dir, 'val.json')):\n",
    "        os.remove(os.path.join(out_dir, 'val.json'))\n",
    "    \n",
    "    licenses = [\n",
    "        {\n",
    "            \"name\": \"\",\n",
    "            \"id\": 0,\n",
    "            \"url\": \"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    info_ = [\n",
    "        {\n",
    "            \"contributor\": \"\",\n",
    "            \"date_created\": \"\",\n",
    "            \"description\": \"\",\n",
    "            \"url\": \"\",\n",
    "            \"version\": \"\",\n",
    "            \"year\": \"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    categories = [\n",
    "        {\n",
    "            \"id\": 0,\n",
    "            \"name\": \"Buoy\",\n",
    "            \"supercategory\": \"\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"name\": \"Boat\",\n",
    "            \"supercategory\": \"\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"name\": \"Channel Marker\",\n",
    "            \"supercategory\": \"\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 3,\n",
    "            \"name\": \"Speed Warning Sign\",\n",
    "            \"supercategory\": \"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    img_idx = 0\n",
    "    annot_idx = 0\n",
    "\n",
    "    imgs_list = []\n",
    "    annots_list = []\n",
    "\n",
    "    for label_file in sorted(os.listdir(label_dir)):\n",
    "        label_file_ = os.path.join(label_dir, label_file)\n",
    "        img_file_ = os.path.join(img_dir, f'{os.path.splitext(label_file)[0]}.jpg')\n",
    "        img = Image.open(img_file_)\n",
    "        image_w, image_h = img.size\n",
    "\n",
    "        imgs_list.append({\n",
    "            'id': img_idx,\n",
    "            'width': image_w,\n",
    "            'height': image_h,\n",
    "            'file_name': f'{os.path.splitext(label_file)[0]}.jpg',\n",
    "            \"license\": 0,\n",
    "            \"flickr_url\": \"\",\n",
    "            \"coco_url\": \"\",\n",
    "            \"date_captured\": 0\n",
    "        })\n",
    "\n",
    "        with open(label_file_, 'r') as label_f:\n",
    "            labels = label_f.readlines()\n",
    "\n",
    "            for label in labels:\n",
    "                cat, xc, yc, label_normalized_w, label_normalized_h = list(map(lambda x: int(x) if len(x) == 1 else float(x), label.split()))\n",
    "                label_w, label_h = image_w * label_normalized_w, image_h * label_normalized_h\n",
    "                xmin, ymin = (image_w * xc) - (label_w / 2), (image_h * yc) - (label_h / 2)\n",
    "                \n",
    "                xmin = 0 if xmin < 0 else xmin\n",
    "                ymin = 0 if ymin < 0 else ymin\n",
    "\n",
    "                annots_list.append({\n",
    "                    'id': annot_idx,\n",
    "                    'image_id': img_idx,\n",
    "                    'category_id': cat,\n",
    "                    'area': int(label_h * label_w),\n",
    "                    'bbox': [\n",
    "                        xmin,\n",
    "                        ymin,\n",
    "                        label_w,\n",
    "                        label_h\n",
    "                    ],\n",
    "                    'iscrowd': 0,\n",
    "                    'attributes': {\n",
    "                        'type': '',\n",
    "                        'occluded': False\n",
    "                    },\n",
    "                    'segmentation': []\n",
    "                })\n",
    "\n",
    "                annot_idx += 1\n",
    "\n",
    "        img_idx += 1\n",
    "\n",
    "    out_dict = {\n",
    "        'licenses': licenses,\n",
    "        'info': info_,\n",
    "        'categories': categories,\n",
    "        'images': imgs_list,\n",
    "        'annotations': annots_list\n",
    "    }\n",
    "    \n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    with open(os.path.join(out_dir, 'val.json'), 'w') as out_f:\n",
    "        print(os.path.join(out_dir, 'val.json'))\n",
    "        json.dump(out_dict, out_f)\n",
    "        \n",
    "    return os.path.join(out_dir, 'val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b9510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_extract(img_dir, label_dir, out_dir)\n",
    "gt_json_path = initial_extract(source_image_dir, source_label_dir, str(Path(source_image_dir).parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f70c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_val_image_dir = '../resources/save_val2/images/'\n",
    "save_val_label_dir = '../resources/save_val2/labels/'\n",
    "\n",
    "os.makedirs(save_val_image_dir, exist_ok=True)\n",
    "os.makedirs(save_val_label_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b16f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# some handy functions to use along widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "# widget packages\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "image_files = sorted(os.listdir(source_image_dir))\n",
    "label_files = sorted([fn for fn in os.listdir(source_label_dir) if fn.endswith(\"txt\")])\n",
    "\n",
    "@interact(index=(0, len(image_files)-1), save=(0,1))\n",
    "def show_sample(index=0, save=0):\n",
    "    global button\n",
    "\n",
    "    image_file = image_files[index]\n",
    "    image_path = os.path.join(source_image_dir, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if save == 1:\n",
    "        label_file = os.path.join(source_label_dir, label_files[index])\n",
    "        new_label_file_name = f\"VAL_{label_files[index]}\"\n",
    "        new_image_file_name = f\"VAL_{image_files[index]}\"\n",
    "\n",
    "        print(save_val_label_dir+new_label_file_name, save_val_image_dir+new_image_file_name)\n",
    "        shutil.copy(label_file, save_val_label_dir+new_label_file_name)\n",
    "        shutil.copy(image_path, save_val_image_dir+new_image_file_name)\n",
    "    \n",
    "    result = get_prediction(image_path, model)\n",
    "    \n",
    "    canvas = visualize_object_predictions(image, result.object_prediction_list)\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86d25590",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_val_image_dir = '../resources/save_fl221024_3/images/'\n",
    "save_val_label_dir = '../resources/save_fl221024_3/labels/'\n",
    "source_image_dir = \"../resources/export_frame/FL_221024_3/\"\n",
    "\n",
    "os.makedirs(save_val_image_dir, exist_ok=True)\n",
    "os.makedirs(save_val_label_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4beb239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c45db3c6524291b4076c27f435e252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=1037), IntSlider(value=0, description='save'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# some handy functions to use along widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "# widget packages\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "size=(1920,1080)\n",
    "image_files = sorted(os.listdir(source_image_dir))\n",
    "# label_files = sorted([fn for fn in os.listdir(source_label_dir) if fn.endswith(\"txt\")])\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1./(size[0])\n",
    "    dh = 1./(size[1])\n",
    "    x = (box[0] + box[1])/2.0 - 1\n",
    "    y = (box[2] + box[3])/2.0 - 1\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)\n",
    "\n",
    "@interact(index=(0, len(image_files)-1), save=(0,1))\n",
    "def show_sample(index=0, save=0):\n",
    "    image_file = image_files[index]\n",
    "    image_path = os.path.join(source_image_dir, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    result = get_prediction(image_path, model)\n",
    "    \n",
    "    if save == 1:\n",
    "        label_file_name = \"FL221024_2_\"+os.path.splitext(image_file)[0]+\".txt\"\n",
    "        image_file_name = f\"FL221024_2_{image_files[index]}\"\n",
    "\n",
    "        shutil.copy(image_path, save_val_image_dir+image_file_name)\n",
    "    \n",
    "        Path(save_val_label_dir+label_file_name).touch()\n",
    "        with open(save_val_label_dir+label_file_name, 'w') as f:    \n",
    "            for object_prediction in result.object_prediction_list:\n",
    "                object_prediction = object_prediction.deepcopy()\n",
    "                bbox = object_prediction.bbox.to_voc_bbox()\n",
    "                category_id = object_prediction.category.id\n",
    "                yolo = convert(size,[bbox[0], bbox[2], bbox[1], bbox[3]])\n",
    "                f.write(f\"{category_id} {yolo[0]} {yolo[1]} {yolo[2]} {yolo[3]}\\n\")\n",
    "                \n",
    "        print(save_val_image_dir+image_file_name, save_val_label_dir+label_file_name)\n",
    "\n",
    "    canvas = visualize_object_predictions(image, result.object_prediction_list)\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be209b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf8075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b9d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ba8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "coco=COCO(gt_json_path)\n",
    "y_offset=-20\n",
    "\n",
    "@interact(index=(0, len(image_files)-1))\n",
    "def draw_gt_bbox(index=0):\n",
    "    fig, ax = plt.subplots()\n",
    "    img = coco.loadImgs(ids=[index])[-1]\n",
    "    I = cv2.imread(os.path.join(source_image_dir, img['file_name']))\n",
    "    I = cv2.cvtColor(I, cv2.COLOR_BGR2RGB)\n",
    "    ax.imshow(I); plt.axis('off')\n",
    "    annIds = coco.getAnnIds(imgIds=img['id'], iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    coco.showAnns(anns, draw_bbox=True)\n",
    "    for i, ann in enumerate(anns):\n",
    "        ax.text(anns[i]['bbox'][0], anns[i]['bbox'][1]+y_offset, anns[i]['category_id'], style='italic', \n",
    "                bbox={'facecolor': 'white', 'alpha': 0.7, 'pad': 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b79211",
   "metadata": {},
   "source": [
    "## remove no label images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218b79f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for image_file in os.listdir(save_val_image_dir):\n",
    "    label_file = save_val_label_dir+os.path.splitext(image_file)[0]+\".txt\"\n",
    "    cnt += os.path.exists(label_file)\n",
    "    if not os.path.exists(label_file):\n",
    "        print(\"label file does not exit\")\n",
    "        os.remove(os.path.join(save_val_image_dir,image_file))\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b05ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(save_val_image_dir)) == len(os.listdir(save_val_label_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502d258f",
   "metadata": {},
   "source": [
    "## 기존 VAL에서 복사한 이미지들 삭제하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in sorted(os.listdir(save_val_image_dir)):\n",
    "    label_file = save_val_label_dir+os.path.splitext(image_name)[0][4:]+\".txt\"\n",
    "    image_file = os.path.join(save_val_image_dir,image_name[4:])\n",
    "    \n",
    "    os.remove(os.path.join(source_image_dir,image_name[4:]))\n",
    "    os.remove(os.path.join(source_label_dir,os.path.splitext(image_name)[0][4:]+\".txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a2e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(save_val_image_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58974966",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(source_image_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e804d5a6",
   "metadata": {},
   "source": [
    "## YOLOv5 인퍼런스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_image_dir = '../resources/log_221017_2_narrow/images/'\n",
    "yolo_label_dir = '../resources/log_221017_2_narrow/labels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd39a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(yolo_image_dir, exist_ok=True)\n",
    "os.makedirs(yolo_label_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a791efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "slice_size=640\n",
    "overlap_ratio=0.25\n",
    "single_row_predict=True\n",
    "single_row_y_start=200\n",
    "postprocess_match_threshold=0.5\n",
    "no_slice_prediction=True\n",
    "cnt=0\n",
    "size=(1920,1080)\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1./(size[0])\n",
    "    dh = 1./(size[1])\n",
    "    x = (box[0] + box[1])/2.0 - 1\n",
    "    y = (box[2] + box[3])/2.0 - 1\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)\n",
    "\n",
    "for image_file in tqdm(sorted(glob(source_image_dir+\"/*.jpg\"))):\n",
    "    \n",
    "    shutil.copy(image_file, yolo_image_dir+os.path.basename(image_file))\n",
    "    label_file_name = os.path.splitext(os.path.basename(image_file))[0]+\".txt\"\n",
    "    \n",
    "    if not no_slice_prediction:\n",
    "        result = get_sliced_prediction(image_file,\n",
    "                                       model,\n",
    "                                       slice_height=slice_size,\n",
    "                                       slice_width=slice_size,\n",
    "                                       postprocess_match_threshold=postprocess_match_threshold,\n",
    "                                       overlap_height_ratio=overlap_ratio,\n",
    "                                       overlap_width_ratio=overlap_ratio,\n",
    "                                       single_row_y_start=single_row_y_start,\n",
    "                                       single_row_predict=single_row_predict,\n",
    "                                       verbose=0)\n",
    "    else:\n",
    "        result = get_prediction(image_file, model)\n",
    "\n",
    "    Path(yolo_label_dir+label_file_name).touch()\n",
    "    with open(yolo_label_dir+label_file_name, 'w') as f:    \n",
    "        for object_prediction in result.object_prediction_list:\n",
    "            object_prediction = object_prediction.deepcopy()\n",
    "            bbox = object_prediction.bbox.to_voc_bbox()\n",
    "            category_id = object_prediction.category.id\n",
    "            yolo = convert(size,[bbox[0], bbox[2], bbox[1], bbox[3]])\n",
    "            f.write(f\"{category_id} {yolo[0]} {yolo[1]} {yolo[2]} {yolo[3]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed46c517",
   "metadata": {},
   "source": [
    "## Visualize yolo bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME_TO_ID = {'Buoy': 0, 'Boat': 1, 'Channel Marker': 2, 'Speed Warning Sign': 3}\n",
    "CLASS_ID_TO_NAME = {0: 'Buoy', 1: 'Boat', 2: 'Channel Marker', 3: 'Speed Warning Sign'}\n",
    "SIZE=(1920,1080)\n",
    "\n",
    "def visualize_yolo(image, bboxes, category_ids, color=None):\n",
    "    image = copy.deepcopy(image)\n",
    "    \n",
    "    if color is None:\n",
    "        colors = Colors()\n",
    "    else:\n",
    "        colors = None\n",
    "        \n",
    "    for bbox, category_id in zip(bboxes, category_ids):\n",
    "        class_name = CLASS_ID_TO_NAME[category_id[0]]\n",
    "        \n",
    "        x_center, y_center, w, h = bbox\n",
    "        x_min = int((x_center - w/2) * SIZE[0])\n",
    "        y_min = int((y_center - h/2) * SIZE[1])\n",
    "        x_max = int((x_center + w/2) * SIZE[0])\n",
    "        y_max = int((y_center + h/2) * SIZE[1])\n",
    "\n",
    "        if colors is not None:\n",
    "            color = colors(category_id[0])\n",
    "        \n",
    "        # set rect_th for boxes\n",
    "        rect_th = max(round(sum(image.shape) / 2 * 0.001), 1)\n",
    "        # set text_th for category names\n",
    "        text_th = max(rect_th - 1, 1)\n",
    "        # set text_size for category names\n",
    "        text_size = rect_th / 3\n",
    "\n",
    "        cv2.rectangle(image, \n",
    "                      (x_min, y_min),\n",
    "                      (x_max, y_max), \n",
    "                      color=color,\n",
    "                      thickness=rect_th)\n",
    "        \n",
    "        p1, p2 = (int(x_min), int(y_min)), (int(x_max), int(y_max))\n",
    "        label = f\"{class_name}\"\n",
    "        w, h = cv2.getTextSize(label, 0, fontScale=text_size, thickness=text_th)[0]  # label width, height\n",
    "        outside = p1[1] - h - 3 >= 0  # label fits outside box\n",
    "        p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "        \n",
    "        cv2.rectangle(image, p1, p2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            label,\n",
    "            (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n",
    "            0,\n",
    "            text_size,\n",
    "            (255, 255, 255),\n",
    "            thickness=text_th,\n",
    "        )\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_label_files = sorted(glob(yolo_label_dir+\"/*.txt\"))\n",
    "infer_image_files = sorted(glob(yolo_image_dir+\"/*.jpg\"))\n",
    "\n",
    "@interact(index=(0,len(infer_image_files)))\n",
    "def verify_gt(index=0):\n",
    "    image = cv2.imread(infer_image_files[index])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    label = infer_label_files[index]\n",
    "    \n",
    "    bboxes = []\n",
    "    category_ids = []\n",
    "    \n",
    "    with open(label, 'r') as f:\n",
    "        line = f.readline().strip()\n",
    "        while line:\n",
    "            id, cx, cy, w, h = list(map(float, line.split()))\n",
    "            bboxes.append([cx, cy, w, h])\n",
    "            category_ids.append([int(id)])\n",
    "            line = f.readline().strip()\n",
    "\n",
    "    if len(bboxes) > 0:    \n",
    "        canvas = visualize_yolo(image, bboxes, category_ids)\n",
    "        plt.figure(figsize=(16,16))\n",
    "        plt.imshow(canvas)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf826fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb3938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
